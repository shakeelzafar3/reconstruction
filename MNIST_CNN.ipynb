{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakeelzafar3/reconstruction/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C9E7Iy372oC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb425891-6e5e-44da-fb51-29f6ff913e3c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"PSO module\n",
        "Copyright (c) 2017 Future Processing sp. z.o.o.\n",
        "@author: Pablo Ribalta Lorenzo\n",
        "@email: pribalta@future-processing.com)\n",
        "@date: 10.04.2017\n",
        "This module encapsulates all the functionality related to Particle\n",
        "Swarm Optimization, including the algorithm itself and the Particles\n",
        "\"\"\"\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "class Particle(object):\n",
        "    \"\"\"Particle class for PSO\n",
        "    This class encapsulates the behavior of each particle in PSO and provides\n",
        "    an efficient way to do bookkeeping about the state of the swarm in any given\n",
        "    iteration.\n",
        "    Args:\n",
        "        lower_bound (np.array): Vector of lower boundaries for particle dimensions.\n",
        "        upper_bound (np.array): Vector of upper boundaries for particle dimensions.\n",
        "        dimensions (int): Number of dimensions of the search space.\n",
        "        objective function (function): Black-box function to evaluate.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 lower_bound,\n",
        "                 upper_bound,\n",
        "                 dimensions,\n",
        "                 objective_function):\n",
        "        self.reset(dimensions, lower_bound, upper_bound, objective_function)\n",
        "\n",
        "    def reset(self,\n",
        "              dimensions,\n",
        "              lower_bound,\n",
        "              upper_bound,\n",
        "              objective_function):\n",
        "        \"\"\"Particle reset\n",
        "        Allows for reset of a particle without reallocation.\n",
        "\t\tArgs:\n",
        "\t\t\tlower_bound (np.array): Vector of lower boundaries for particle dimensions.\n",
        "\t\t\tupper_bound (np.array): Vector of upper boundaries for particle dimensions.\n",
        "\t\t\tdimensions (int): Number of dimensions of the search space.\n",
        "        \"\"\"\n",
        "        position = []\n",
        "        for i in range(dimensions):\n",
        "            if lower_bound[i] < upper_bound[i]:\n",
        "                position.extend(np.random.randint(lower_bound[i], upper_bound[i] + 1, 1, dtype=int))\n",
        "            elif lower_bound[i] == upper_bound[i]:\n",
        "                position.extend(np.array([lower_bound[i]], dtype=int))\n",
        "            else:\n",
        "                assert False\n",
        "\n",
        "        self.position = [position]\n",
        "\n",
        "        self.velocity = [np.multiply(np.random.rand(dimensions),\n",
        "                                     (upper_bound - lower_bound)).astype(int)]\n",
        "\n",
        "        self.best_position = self.position[:]\n",
        "\n",
        "        self.function_value = [objective_function(self.best_position[-1])]\n",
        "        self.best_function_value = self.function_value[:]\n",
        "\n",
        "    def update_velocity(self, omega, phip, phig, best_swarm_position):\n",
        "        \"\"\"Particle velocity update\n",
        "\t\tArgs:\n",
        "\t\t\tomega (float): Velocity equation constant.\n",
        "\t\t\tphip (float): Velocity equation constant.\n",
        "\t\t\tphig (float): Velocity equation constant.\n",
        "\t\t\tbest_swarm_position (np.array): Best particle position.\n",
        "        \"\"\"\n",
        "        random_coefficient_p = np.random.uniform(size=np.asarray(self.position[-1]).shape)\n",
        "        random_coefficient_g = np.random.uniform(size=np.asarray(self.position[-1]).shape)\n",
        "\n",
        "        self.velocity.append(omega\n",
        "                             * np.asarray(self.velocity[-1])\n",
        "                             + phip\n",
        "                             * random_coefficient_p\n",
        "                             * (np.asarray(self.best_position[-1])\n",
        "                                - np.asarray(self.position[-1]))\n",
        "                             + phig\n",
        "                             * random_coefficient_g\n",
        "                             * (np.asarray(best_swarm_position)\n",
        "                                - np.asarray(self.position[-1])))\n",
        "\n",
        "        self.velocity[-1] = self.velocity[-1].astype(int)\n",
        "\n",
        "    def update_position(self, lower_bound, upper_bound, objective_function):\n",
        "        \"\"\"Particle position update\n",
        "\t\tArgs:\n",
        "\t\t\tlower_bound (np.array): Vector of lower boundaries for particle dimensions.\n",
        "\t\t\tupper_bound (np.array): Vector of upper boundaries for particle dimensions.\n",
        "\t\t\tobjective function (function): Black-box function to evaluate.\n",
        "        \"\"\"\n",
        "        new_position = self.position[-1] + self.velocity[-1]\n",
        "\n",
        "        if np.array_equal(self.position[-1], new_position):\n",
        "            self.function_value.append(self.function_value[-1])\n",
        "        else:\n",
        "            mark1 = new_position < lower_bound\n",
        "            mark2 = new_position > upper_bound\n",
        "\n",
        "            new_position[mark1] = lower_bound[mark1]\n",
        "            new_position[mark2] = upper_bound[mark2]\n",
        "\n",
        "            self.function_value.append(objective_function(self.position[-1]))\n",
        "\n",
        "        self.position.append(new_position.tolist())\n",
        "\n",
        "        if self.function_value[-1] < self.best_function_value[-1]:\n",
        "            self.best_position.append(self.position[-1][:])\n",
        "            self.best_function_value.append(self.function_value[-1])\n",
        "\n",
        "class Pso(object):\n",
        "    \"\"\"PSO wrapper\n",
        "    This class contains the particles and provides an abstraction to hold all the context\n",
        "    of the PSO algorithm\n",
        "    Args:\n",
        "        swarmsize (int): Number of particles in the swarm\n",
        "        maxiter (int): Maximum number of generations the swarm will run\n",
        "    \"\"\"\n",
        "    def __init__(self, swarmsize=100, maxiter=100):\n",
        "        self.max_generations = maxiter\n",
        "        self.swarmsize = swarmsize\n",
        "\n",
        "        self.omega = 0.5\n",
        "        self.phip = 0.5\n",
        "        self.phig = 0.5\n",
        "\n",
        "        self.minstep = 1e-4\n",
        "        self.minfunc = 1e-4\n",
        "\n",
        "        self.best_position = [None]\n",
        "        self.best_function_value = [1]\n",
        "\n",
        "        self.particles = []\n",
        "\n",
        "        self.retired_particles = []\n",
        "\n",
        "    def run(self, function, lower_bound, upper_bound, kwargs=None):\n",
        "        \"\"\"Perform a particle swarm optimization (PSO)\n",
        "\t\tArgs:\n",
        "\t\t\tobjective_function (function): The function to be minimized.\n",
        "\t\t\tlower_bound (np.array): Vector of lower boundaries for particle dimensions.\n",
        "\t\t\tupper_bound (np.array): Vector of upper boundaries for particle dimensions.\n",
        "\t\tReturns:\n",
        "\t\t\tbest_position (np.array): Best known position\n",
        "\t\t\taccuracy (float): Objective value at best_position\n",
        "\t\t\t:param kwargs:\n",
        "        \"\"\"\n",
        "        if kwargs is None:\n",
        "            kwargs = {}\n",
        "\n",
        "        objective_function = lambda x: function(x, **kwargs)\n",
        "        assert hasattr(function, '__call__'), 'Invalid function handle'\n",
        "\n",
        "        assert len(lower_bound) == len(upper_bound), 'Invalid bounds length'\n",
        "\n",
        "        lower_bound = np.array(lower_bound)\n",
        "        upper_bound = np.array(upper_bound)\n",
        "\n",
        "        assert np.all(upper_bound > lower_bound), 'Invalid boundary values'\n",
        "\n",
        "\n",
        "        dimensions = len(lower_bound)\n",
        "\n",
        "        self.particles = self.initialize_particles(lower_bound,\n",
        "                                                   upper_bound,\n",
        "                                                   dimensions,\n",
        "                                                   objective_function)\n",
        "\n",
        "        # Start evolution\n",
        "        generation = 1\n",
        "        while generation <= self.max_generations:\n",
        "            for particle in self.particles:\n",
        "                particle.update_velocity(self.omega, self.phip, self.phig, self.best_position[-1])\n",
        "                particle.update_position(lower_bound, upper_bound, objective_function)\n",
        "\n",
        "                if particle.best_function_value[-1] == 0:\n",
        "                    self.retired_particles.append(copy.deepcopy(particle))\n",
        "                    particle.reset(dimensions, lower_bound, upper_bound, objective_function)\n",
        "                elif particle.best_function_value[-1] < self.best_function_value[-1]:\n",
        "                    stepsize = np.sqrt(np.sum((np.asarray(self.best_position[-1])\n",
        "                                               - np.asarray(particle.position[-1])) ** 2))\n",
        "\n",
        "                    if np.abs(np.asarray(self.best_function_value[-1])\n",
        "                              - np.asarray(particle.best_function_value[-1])) \\\n",
        "                            <= self.minfunc:\n",
        "                        return particle.best_position[-1], particle.best_function_value[-1]\n",
        "                    elif stepsize <= self.minstep:\n",
        "                        return particle.best_position[-1], particle.best_function_value[-1]\n",
        "                    else:\n",
        "                        self.best_function_value.append(particle.best_function_value[-1])\n",
        "                        self.best_position.append(particle.best_position[-1][:])\n",
        "\n",
        "\n",
        "\n",
        "            generation += 1\n",
        "\n",
        "        return self.best_position[-1], self.best_function_value[-1]\n",
        "\n",
        "    def initialize_particles(self,\n",
        "                             lower_bound,\n",
        "                             upper_bound,\n",
        "                             dimensions,\n",
        "                             objective_function):\n",
        "        \"\"\"Initializes the particles for the swarm\n",
        "\t\tArgs:\n",
        "\t\t\tobjective_function (function): The function to be minimized.\n",
        "\t\t\tlower_bound (np.array): Vector of lower boundaries for particle dimensions.\n",
        "\t\t\tupper_bound (np.array): Vector of upper boundaries for particle dimensions.\n",
        "\t\t\tdimensions (int): Number of dimensions of the search space.\n",
        "\t\tReturns:\n",
        "\t\t\tparticles (list): Collection or particles in the swarm\n",
        "        \"\"\"\n",
        "        particles = []\n",
        "        for _ in range(self.swarmsize):\n",
        "            particles.append(Particle(lower_bound,\n",
        "                                      upper_bound,\n",
        "                                      dimensions,\n",
        "                                      objective_function))\n",
        "            if particles[-1].best_function_value[-1] < self.best_function_value[-1]:\n",
        "                self.best_function_value.append(particles[-1].best_function_value[-1])\n",
        "                self.best_position.append(particles[-1].best_position[-1])\n",
        "\n",
        "\n",
        "        self.best_position = [self.best_position[-1]]\n",
        "        self.best_function_value = [self.best_function_value[-1]]\n",
        "\n",
        "        return particles\n",
        "\n",
        "\n",
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def func(x):\n",
        "  n,sf,sp,l = x[0],x[1],x[2],x[3]\n",
        " \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32,kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(n, (sf, sf), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(sp, sp),strides=(l,l)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  cp = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')];\n",
        "\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=0,\n",
        "            validation_data=(x_test, y_test),callbacks=cp)\n",
        "  \n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "  # loss, val\n",
        "  print('current config:',x,'val:',score[1])\n",
        "  return score[1]\n",
        "\n",
        "##################################################################\n",
        "pso = Pso(swarmsize=4,maxiter=14)\n",
        "# n,sf,sp,l\n",
        "bp,value = pso.run(func,[1,2,2,2],[16,8,4,4])\n",
        "\n",
        "v = func(bp);\n",
        "\n",
        "##################################################################\n",
        "\n",
        "print('Test loss:', bp)\n",
        "print('Test accuracy:', value,v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "current config: [10, 8, 4, 4] val: 0.9886000156402588\n",
            "current config: [3, 7, 2, 2] val: 0.9846000075340271\n",
            "current config: [14, 6, 3, 2] val: 0.989300012588501\n",
            "current config: [12, 6, 4, 2] val: 0.9879000186920166\n",
            "current config: [10, 8, 4, 4] val: 0.9884999990463257\n",
            "current config: [3, 7, 2, 2] val: 0.9861000180244446\n",
            "current config: [14, 6, 3, 2] val: 0.9909999966621399\n",
            "current config: [12, 6, 4, 2] val: 0.9918000102043152\n",
            "current config: [11, 8, 4, 4] val: 0.9873999953269958\n",
            "current config: [11, 8, 3, 2] val: 0.9907000064849854\n",
            "current config: [16, 7, 4, 2] val: 0.9919999837875366\n",
            "current config: [10, 8, 4, 4] val: 0.9898999929428101\n",
            "current config: [5, 8, 2, 2] val: 0.9894000291824341\n",
            "current config: [7, 8, 3, 2] val: 0.9894999861717224\n",
            "current config: [15, 7, 4, 2] val: 0.9901000261306763\n",
            "current config: [7, 8, 4, 4] val: 0.9886000156402588\n",
            "current config: [6, 8, 3, 2] val: 0.989799976348877\n",
            "current config: [10, 7, 4, 2] val: 0.9907000064849854\n",
            "current config: [5, 8, 4, 4] val: 0.9896000027656555\n",
            "current config: [5, 8, 3, 2] val: 0.9894000291824341\n",
            "current config: [7, 7, 4, 2] val: 0.9896000027656555\n",
            "current config: [7, 8, 3, 2] val: 0.9896000027656555\n",
            "current config: [4, 8, 4, 4] val: 0.9891999959945679\n",
            "current config: [8, 8, 3, 2] val: 0.9891999959945679\n",
            "current config: [5, 8, 4, 4] val: 0.9883000254631042\n",
            "current config: [7, 8, 4, 4] val: 0.9890999794006348\n",
            "current config: [10, 8, 3, 2] val: 0.9908000230789185\n",
            "current config: [8, 8, 4, 4] val: 0.988099992275238\n",
            "current config: [8, 7, 4, 2] val: 0.9919999837875366\n",
            "current config: [3, 7, 2, 2] val: 0.9890999794006348\n",
            "Test loss: [3, 7, 2, 2]\n",
            "Test accuracy: 0.9846000075340271 0.9890999794006348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fff-E63J8a53"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}